{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "43425a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 32, 32)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "\n",
    "#initiate the input as Batch_size, Channel, height, width 1*3*32*32\n",
    "inputs = torch.randn(1,3, 32, 32)\n",
    "inputs.shape\n",
    "input_np = inputs.numpy()\n",
    "input_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded05ba8",
   "metadata": {},
   "source": [
    "#  Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8e23c315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 31, 31)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MaxPool=torch.nn.MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, return_indices=False, ceil_mode=False)\n",
    "torch_out=MaxPool(inputs)\n",
    "torch_out = torch_out.numpy()\n",
    "torch_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97212937",
   "metadata": {},
   "source": [
    " \n",
    "    2D Pooling\n",
    "    Parameters:\n",
    "        A: input 2D array\n",
    "        kernel_size: int, the size of the window\n",
    "        stride: int, the stride of the window\n",
    "        padding: int, implicit zero paddings on both sides of the input\n",
    "        pool_mode: string, 'max' or 'avg'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "233ad0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 31, 31)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pool2d(img, kernel_size, stride, padding, pool_mode='max'):\n",
    "    \n",
    "    my_out = np.empty((1,3,(img.shape[2] - kernel_size)//stride + 1,\n",
    "                    (img.shape[3] - kernel_size)//stride + 1), dtype = float)\n",
    "    \n",
    "    for batch in img:\n",
    "        i = 0\n",
    "        for A in batch:\n",
    "            A = np.pad(A, padding, mode='constant')\n",
    "            \n",
    "            output_shape = ((A.shape[0] - kernel_size)//stride + 1,\n",
    "                    (A.shape[1] - kernel_size)//stride + 1)\n",
    "            kernel_sizes = (kernel_size, kernel_size)\n",
    "            A_w = as_strided(A, shape = output_shape + kernel_sizes, \n",
    "                        strides = (stride*A.strides[0],\n",
    "                                   stride*A.strides[1]) + A.strides)\n",
    "            A_w = A_w.reshape(-1, *kernel_sizes)\n",
    "\n",
    "\n",
    "            if pool_mode == 'max':\n",
    "                my_out[0,i] = A_w.max(axis=(1,2)).reshape(output_shape)\n",
    "            elif pool_mode == 'avg':\n",
    "                my_out[0,i] =  A_w.mean(axis=(1,2)).reshape(output_shape)\n",
    "            i+=1\n",
    "    return my_out\n",
    "\n",
    "my_out = pool2d(input_np, kernel_size=2, stride=1, padding=0, pool_mode='max')\n",
    "my_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3dcc885c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]]]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_out == my_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09cf189",
   "metadata": {},
   "source": [
    "#  Average pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4b074116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 31, 31)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AvgPool=torch.nn.AvgPool2d(kernel_size=2, stride=1, padding=0,ceil_mode=False, count_include_pad=True,divisor_override=None)\n",
    "torch_out=AvgPool(inputs)\n",
    "torch_out = torch_out.numpy()\n",
    "torch_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b9b3067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool2d(A, kernel_size, stride, padding, pool_mode='max'):\n",
    "    \n",
    "    A = np.pad(A, padding, mode='constant')\n",
    "\n",
    "    output_shape = ((A.shape[0] - kernel_size)//stride + 1,\n",
    "                    (A.shape[1] - kernel_size)//stride + 1)\n",
    "    kernel_size = (kernel_size, kernel_size)\n",
    "    A_w = as_strided(A, shape = output_shape + kernel_size, \n",
    "                        strides = (stride*A.strides[0],\n",
    "                                   stride*A.strides[1]) + A.strides)\n",
    "    A_w = A_w.reshape(-1, *kernel_size)\n",
    "\n",
    "    if pool_mode == 'max':\n",
    "        return A_w.max(axis=(1,2)).reshape(output_shape)\n",
    "    elif pool_mode == 'avg':\n",
    "        return A_w.mean(axis=(1,2)).reshape(output_shape)\n",
    "\n",
    "my_out = np.empty((1,3,31,31), dtype = float)\n",
    "for batch in input_np:\n",
    "    i = 0\n",
    "    for channel in batch:\n",
    "        my_out[0,i] =  pool2d(channel, kernel_size=2, stride=1, padding=0, pool_mode='avg')\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "75497952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]]]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_out == my_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e651e17",
   "metadata": {},
   "source": [
    "# Conv NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dd4cc35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 30, 30])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "Conv=torch.nn.Conv2d(in_channels=3, out_channels=6,kernel_size=3, stride=1, padding=0, dilation=1, groups=1,\n",
    "                     bias=True, padding_mode='zeros')\n",
    "torch_out=Conv(inputs)\n",
    "torch_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bd4e7ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 30, 30])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = Conv.weight.data\n",
    "bias = Conv.bias.data\n",
    "def conv2d(inputs, weight, bias, stride):\n",
    "    padding = 0\n",
    "    N, C, H, W = inputs.shape\n",
    "    filter_, _, kernel_H, kernel_W = weight.shape\n",
    "    \n",
    "    H_out= 1+(H+2*padding-kernel_H)//stride\n",
    "    W_out= 1+(W+2*padding-kernel_W)//stride\n",
    "    out = torch.zeros(N, filter_, H_out, W_out)\n",
    "    \n",
    "    for batch in range(N):\n",
    "        for filter_i in range(filter_):\n",
    "            for row in range(H_out):\n",
    "                for col in range(W_out):\n",
    "                    out[batch, filter_i, row, col] = torch.sum(inputs[batch, :, row*stride:row*stride + kernel_H, \n",
    "                                                                     col*stride:col*stride + kernel_W] *weight[filter_i, :,:,:]) + bias[filter_i]\n",
    "                    \n",
    "    return out\n",
    "\n",
    "my_out = conv2d(inputs, weight, bias, 1)\n",
    "my_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1fbf5b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_out - my_out<=0.000001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5af85a",
   "metadata": {},
   "source": [
    "#  Conv 2D with Dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ba279d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-6.7205e-01,  6.9666e-01, -5.0877e-01, -3.7890e-02, -2.4523e-01,\n",
       "            8.1609e-02,  4.2619e-01, -9.0766e-01,  3.3815e-01, -5.6090e-01,\n",
       "           -1.0934e-01,  3.2475e-02],\n",
       "          [ 6.2436e-01,  5.6893e-02, -6.0532e-01, -3.9386e-01,  1.5883e-01,\n",
       "            3.4871e-01,  5.1953e-01,  2.8136e-01, -8.8076e-02,  3.3201e-01,\n",
       "           -5.2483e-01, -4.8972e-01],\n",
       "          [ 3.2871e-01,  7.7371e-01,  6.6600e-01, -1.1036e+00,  1.8207e-01,\n",
       "            6.3458e-01, -1.8130e-01,  6.8301e-01, -9.6772e-02,  1.1915e+00,\n",
       "           -8.5092e-01, -7.4201e-02],\n",
       "          [ 1.4339e-01, -3.6058e-02, -9.2370e-02,  7.9441e-01,  7.6642e-01,\n",
       "            9.4264e-01, -6.5509e-01, -2.0474e-01,  1.2391e+00, -8.2072e-01,\n",
       "            9.3929e-01,  1.8113e-01],\n",
       "          [ 4.3519e-01,  1.0018e+00, -1.0260e+00,  7.6188e-01,  7.7489e-02,\n",
       "            8.3154e-01, -1.0570e+00, -1.4593e-01, -6.2887e-01, -6.4637e-02,\n",
       "            2.4616e-01,  5.9856e-01],\n",
       "          [-6.4982e-01,  1.0849e-02,  6.0189e-01, -5.7040e-01, -2.5203e-01,\n",
       "           -2.0859e-01, -7.7485e-02, -3.7664e-01,  7.2038e-01, -9.9650e-01,\n",
       "            5.9358e-01,  4.3492e-01],\n",
       "          [-9.1684e-02, -8.8711e-01,  3.8068e-01,  4.2393e-01, -1.1071e+00,\n",
       "           -1.8169e-01, -3.9336e-02,  4.2578e-01,  8.3067e-01,  1.1307e+00,\n",
       "           -4.5076e-01,  5.9938e-01],\n",
       "          [ 1.3455e+00,  6.7979e-01, -3.5559e-04,  3.8856e-01,  6.4437e-01,\n",
       "           -5.0198e-01, -6.2158e-02, -2.9486e-02, -3.1443e-01, -1.9590e-01,\n",
       "           -6.7346e-01, -5.0313e-01],\n",
       "          [ 8.2777e-01, -6.2951e-01, -6.4754e-01, -8.7086e-01, -5.3620e-01,\n",
       "           -9.6251e-02,  1.2400e-01,  7.4044e-01,  1.2076e-01,  4.6812e-01,\n",
       "           -2.4274e-02,  9.8217e-01],\n",
       "          [ 4.5666e-01,  1.1301e-02,  3.0182e-01, -4.7713e-01,  8.7395e-01,\n",
       "           -5.2379e-01,  4.2323e-01, -1.1894e-01, -6.9544e-02, -1.4574e-01,\n",
       "           -5.8335e-01,  7.3448e-01],\n",
       "          [-4.3563e-01, -1.1726e+00, -2.8136e-01,  8.4947e-01,  4.5537e-01,\n",
       "           -4.4767e-01,  1.9758e-01, -1.6297e-01,  6.5518e-01, -3.2415e-01,\n",
       "           -3.6094e-01,  3.6618e-01],\n",
       "          [ 2.7700e-01,  2.6507e-01, -4.3787e-01, -1.0058e+00,  4.7445e-03,\n",
       "           -1.5085e-01, -4.9257e-01, -2.0462e-01, -6.3814e-01,  9.6976e-02,\n",
       "           -3.8779e-01,  7.3469e-01]],\n",
       "\n",
       "         [[-7.3027e-01, -5.0367e-01, -1.5592e-01,  5.7988e-01,  5.7776e-02,\n",
       "           -1.2765e-01,  3.5176e-01, -5.7586e-01, -1.2417e-01, -5.2011e-01,\n",
       "            3.3253e-01,  3.4006e-01],\n",
       "          [ 2.4551e-01, -2.1510e-01,  6.6515e-01, -3.9399e-02,  1.4283e-02,\n",
       "           -4.7614e-01, -1.1327e-01, -2.1384e-01,  1.7876e-01, -6.1574e-02,\n",
       "            2.9337e-01,  8.1531e-01],\n",
       "          [-3.5541e-01, -2.8772e-01, -1.2357e-02, -2.3044e-01,  1.1645e+00,\n",
       "            1.1554e-02, -7.4208e-01, -4.7930e-01,  7.9665e-01, -2.3027e-01,\n",
       "           -6.3339e-01,  1.2518e+00],\n",
       "          [-1.4444e+00,  6.4645e-01, -1.7899e-01,  1.6629e-01, -3.2701e-01,\n",
       "            2.8914e-01, -8.6963e-01,  1.2605e-01,  9.6556e-01, -8.3523e-01,\n",
       "           -4.3442e-01,  7.3513e-01],\n",
       "          [-6.4711e-01, -5.5644e-01,  2.3915e-01, -4.2356e-01, -1.2149e+00,\n",
       "           -6.2686e-01,  1.1744e-01, -2.8295e-02, -2.3188e-02, -1.1136e+00,\n",
       "           -3.9178e-01, -1.2112e-01],\n",
       "          [ 8.2422e-02, -1.3503e+00,  1.9820e-01, -1.5923e-01,  2.9376e-01,\n",
       "           -2.9506e-01, -5.7527e-01,  6.3136e-02, -2.0237e-01,  1.0645e+00,\n",
       "           -7.0298e-01, -3.2713e-02],\n",
       "          [-2.9012e-01, -4.2412e-01, -4.0330e-01, -9.0063e-01,  3.5605e-01,\n",
       "           -2.5438e-01,  1.4967e+00,  2.0378e-02, -4.8262e-01, -2.0645e-01,\n",
       "           -4.9091e-01, -5.2497e-01],\n",
       "          [-6.2565e-02,  9.5195e-02,  1.9944e-02,  8.2481e-01,  5.4993e-01,\n",
       "           -9.8231e-01, -2.2754e-01,  1.5423e-01, -1.5635e-01,  7.7450e-01,\n",
       "            8.1970e-01, -3.8472e-01],\n",
       "          [ 8.6040e-02, -4.7582e-01, -3.0575e-01, -2.4865e-01,  1.0841e-02,\n",
       "            4.0910e-01,  2.5189e-01,  2.0973e-01, -3.3921e-01,  3.5835e-02,\n",
       "            9.6505e-01, -5.1768e-01],\n",
       "          [-5.2470e-01, -5.3361e-02, -7.4604e-01,  3.7049e-02, -8.0600e-02,\n",
       "            2.5469e-01,  4.1170e-02,  2.2930e-01, -3.3408e-01,  4.0434e-01,\n",
       "            5.1574e-01, -1.1893e-01],\n",
       "          [ 2.4161e-01,  4.5966e-01,  3.2727e-02,  2.6945e-01, -4.2059e-02,\n",
       "           -1.4860e-02,  4.5440e-01, -1.5424e-01,  8.4496e-01,  1.6328e-01,\n",
       "            8.3489e-02,  1.1615e-01],\n",
       "          [-4.5997e-01,  1.1552e-01,  1.0303e+00, -2.9112e-02, -1.3089e+00,\n",
       "            3.2998e-01,  3.4280e-01, -4.4130e-02,  2.3310e-01, -4.9691e-01,\n",
       "            6.8717e-01, -7.9400e-02]],\n",
       "\n",
       "         [[-5.2890e-01, -6.5919e-01, -8.1335e-02,  1.6073e-01,  2.2464e-01,\n",
       "            6.9639e-01,  2.6958e-01,  7.0962e-03, -2.1184e-02,  3.6287e-01,\n",
       "           -5.2197e-01,  2.3983e-02],\n",
       "          [ 1.5726e-01,  1.2720e-01, -1.2707e-01, -2.7525e-01, -1.0884e+00,\n",
       "           -2.6033e-01, -1.2029e+00, -1.9073e-01, -6.6164e-01, -9.2987e-01,\n",
       "           -3.8076e-01, -8.7490e-01],\n",
       "          [-2.3429e-01, -1.9576e-02, -5.6148e-01, -6.9825e-02, -1.9858e-01,\n",
       "            1.9136e-01, -2.4608e-01,  4.4442e-01,  3.5514e-01, -2.9468e-01,\n",
       "           -4.2092e-01,  1.4033e+00],\n",
       "          [ 3.1741e-01,  9.0054e-01,  3.5665e-01,  1.7085e-01,  1.3658e-01,\n",
       "           -2.2635e-01,  3.0685e-01,  3.1527e-02,  1.3652e+00, -5.0263e-01,\n",
       "            1.0076e+00,  6.3959e-01],\n",
       "          [-1.1465e+00,  2.3481e-01,  4.3839e-01,  5.1311e-01,  1.8746e+00,\n",
       "            1.0591e+00,  3.2788e-01,  1.0474e+00, -5.0655e-01,  5.2533e-02,\n",
       "           -1.1782e+00,  1.4025e+00],\n",
       "          [-2.5618e-02, -8.5647e-01,  4.5521e-01, -3.9049e-01,  1.2038e-01,\n",
       "           -1.3918e-03, -1.1127e-03, -2.7469e-01,  1.0433e+00,  1.3070e+00,\n",
       "            1.5187e+00, -7.3346e-01],\n",
       "          [-4.8669e-01, -5.8018e-02,  5.4785e-01,  3.5187e-01, -1.1113e+00,\n",
       "           -6.4756e-01, -6.3405e-02,  6.5448e-01,  1.2834e-01,  9.0212e-01,\n",
       "           -5.2198e-01, -1.2562e+00],\n",
       "          [-5.6363e-02, -9.8644e-01, -1.2900e+00, -5.8888e-01, -1.5661e-01,\n",
       "           -6.0439e-01, -6.0571e-02, -1.6543e-01, -8.2089e-03,  1.8829e-02,\n",
       "            5.3089e-01, -5.5485e-01],\n",
       "          [ 8.2295e-01,  5.8250e-01, -4.3054e-03, -3.1922e-01, -1.5907e-01,\n",
       "           -3.8588e-01,  4.1583e-01,  7.5387e-01, -6.7102e-01, -1.2800e+00,\n",
       "           -7.3912e-01,  5.3400e-01],\n",
       "          [-5.5000e-01,  3.6235e-01, -1.8693e-01, -4.0040e-01,  2.1038e-01,\n",
       "           -4.1223e-02,  5.2913e-01, -1.8546e-01, -3.8950e-01,  1.5718e-01,\n",
       "            2.7970e-01,  1.2704e+00],\n",
       "          [-3.8298e-01, -5.4841e-02, -6.1076e-01, -6.1446e-02,  2.1672e-01,\n",
       "            7.6985e-01, -1.1245e+00, -7.0782e-01, -1.1157e+00, -1.1985e-01,\n",
       "           -9.4216e-01, -1.2835e+00],\n",
       "          [-2.5544e-01, -1.1441e+00,  1.6443e-01,  1.8261e-02, -4.9279e-01,\n",
       "            3.8021e-01,  5.9442e-01, -7.5210e-01, -8.1439e-01, -8.9056e-01,\n",
       "           -5.7925e-01,  3.1479e-01]],\n",
       "\n",
       "         [[ 2.5376e-02,  1.6319e-01,  6.2676e-01, -2.0871e-01, -1.6124e-01,\n",
       "            5.1404e-01,  1.0051e-01,  1.5059e-02,  4.8149e-02,  8.9085e-02,\n",
       "           -1.8993e-01, -1.6063e-01],\n",
       "          [ 6.2120e-01,  6.6639e-01, -3.4460e-01, -1.3055e-01,  5.3895e-01,\n",
       "            6.6212e-01,  1.1427e-01, -3.2113e-01,  8.9850e-01, -1.7020e-01,\n",
       "           -8.1887e-01,  3.5111e-01],\n",
       "          [ 7.6722e-01,  5.0662e-02, -6.7168e-01,  1.4286e-01,  4.0315e-01,\n",
       "           -4.2597e-03, -1.1956e+00,  6.0848e-01, -9.0894e-01, -6.1425e-01,\n",
       "           -8.4676e-01, -5.5761e-01],\n",
       "          [ 1.2619e-01, -3.2555e-02,  4.3544e-01,  5.4264e-01,  6.1410e-02,\n",
       "            1.4392e-01, -3.6162e-02, -9.5187e-01, -5.0276e-01, -4.9537e-01,\n",
       "            2.3754e-01,  7.6488e-01],\n",
       "          [ 1.1462e+00, -2.0496e-02, -1.9182e-01, -2.2034e-01,  1.6565e-01,\n",
       "            1.8566e-01,  9.0330e-01,  1.2145e+00, -2.2098e-01,  7.4620e-01,\n",
       "            7.0384e-01, -3.4788e-01],\n",
       "          [ 1.9464e-01, -6.7792e-01,  9.9185e-01, -2.5504e-01,  4.8866e-01,\n",
       "            1.1880e-01, -1.8642e-02,  4.7043e-02,  7.8961e-01,  4.3810e-01,\n",
       "           -1.4464e-01, -1.7526e-01],\n",
       "          [ 1.1247e+00, -8.2698e-01,  7.6209e-02,  5.8359e-01, -7.9799e-01,\n",
       "           -5.0766e-01, -3.0304e-01,  4.9187e-01, -4.2979e-01,  1.3753e+00,\n",
       "            3.3792e-02, -1.0070e+00],\n",
       "          [ 2.2768e-02, -7.6632e-01,  4.4662e-01, -2.3391e-01,  4.0546e-01,\n",
       "            8.1425e-01,  4.8306e-01,  1.5078e-01,  1.5743e-01,  9.4849e-04,\n",
       "            4.0271e-01, -3.6037e-01],\n",
       "          [ 1.1191e-01, -7.4004e-01, -6.2127e-03, -2.4848e-01, -2.1454e-01,\n",
       "           -6.8261e-01,  7.7673e-02,  7.5046e-01,  6.7679e-01, -9.2583e-02,\n",
       "            1.2608e+00,  1.6597e-01],\n",
       "          [-4.5190e-01, -8.0746e-01, -5.6925e-01, -3.8100e-01,  5.8905e-01,\n",
       "            5.0404e-01,  4.0713e-01, -4.8072e-01,  3.0190e-01,  6.9355e-02,\n",
       "            1.5715e+00,  8.3933e-01],\n",
       "          [-8.7551e-02,  1.0417e+00,  2.4482e-01, -1.4599e-01,  8.4179e-02,\n",
       "            6.7651e-01,  5.7687e-01,  3.5772e-01,  4.5739e-01,  9.8245e-01,\n",
       "            4.8280e-01,  3.9436e-01],\n",
       "          [ 4.1457e-01,  7.5537e-01, -1.8520e-01, -6.6901e-01, -3.0914e-01,\n",
       "            9.1653e-01, -1.4656e-01,  2.8563e-02, -7.2327e-01, -9.0261e-02,\n",
       "           -1.1129e+00, -9.1251e-02]],\n",
       "\n",
       "         [[ 1.8803e-01,  2.1684e-01,  9.8001e-01, -8.2652e-01,  1.0779e-01,\n",
       "            7.6894e-01,  1.1247e-01, -4.0833e-01,  3.7630e-02,  4.9627e-01,\n",
       "           -3.1204e-01,  8.6397e-01],\n",
       "          [-6.5820e-01,  4.4563e-01,  4.0588e-01, -5.7009e-01,  1.0498e+00,\n",
       "            6.9169e-01, -5.4973e-01, -1.5273e-01,  6.6583e-01, -8.9778e-01,\n",
       "           -3.5812e-01,  9.8160e-01],\n",
       "          [ 4.9277e-01,  1.5016e-01, -7.4315e-01, -2.1890e-01,  4.8781e-01,\n",
       "            3.9351e-01, -4.9634e-01,  5.2443e-01,  7.1662e-01, -7.4248e-01,\n",
       "            4.3938e-02,  6.8254e-02],\n",
       "          [ 5.3476e-01, -3.6549e-02,  1.3523e-01,  2.5943e-01,  3.8502e-01,\n",
       "            4.7982e-02, -1.6184e-01,  3.4961e-01,  7.8778e-02,  7.5478e-01,\n",
       "            8.7988e-01,  4.2299e-01],\n",
       "          [-2.0653e-01, -1.1936e+00,  6.8872e-02, -9.4410e-02,  4.9724e-02,\n",
       "            2.7211e-01, -7.5674e-02, -9.1852e-01, -3.9042e-01,  3.4857e-01,\n",
       "           -3.1167e-01, -5.4956e-01],\n",
       "          [ 5.1748e-02,  2.6464e-01, -9.1605e-01,  2.1229e-01,  8.9247e-01,\n",
       "           -7.2642e-01, -1.8022e-01, -7.1954e-01, -1.4874e-01,  4.7678e-01,\n",
       "            2.0320e-01,  3.8618e-01],\n",
       "          [-2.4740e-02,  4.8828e-01, -2.8796e-02, -5.1223e-01, -9.9737e-01,\n",
       "            1.5050e-01,  1.2172e+00,  3.6795e-01, -1.3390e-01,  6.0861e-01,\n",
       "           -1.7307e-01, -6.1473e-01],\n",
       "          [-3.2213e-01, -3.1331e-02,  6.3303e-01,  1.1299e+00,  6.0478e-01,\n",
       "            2.9558e-01,  7.0055e-01,  5.3214e-01, -4.3844e-01, -4.8836e-01,\n",
       "           -1.0033e+00, -8.2306e-02],\n",
       "          [-3.0873e-02,  5.3931e-01, -3.1767e-01,  3.1546e-01, -1.9717e-02,\n",
       "            4.2696e-01, -3.8255e-03, -3.5957e-01,  5.2971e-01,  1.7726e-01,\n",
       "            2.1046e-01,  1.6542e-02],\n",
       "          [-3.7197e-01, -5.1100e-02,  4.2823e-01,  3.0525e-01, -3.7989e-01,\n",
       "            6.5999e-01,  8.9861e-01,  3.7551e-01, -3.2365e-02, -6.2269e-01,\n",
       "            4.7986e-01, -1.8032e-01],\n",
       "          [-2.7058e-01,  6.5943e-01,  5.4721e-01, -3.6574e-01, -4.5872e-01,\n",
       "            4.7253e-01, -1.4386e-01,  1.0522e+00, -6.7757e-02,  2.3113e-01,\n",
       "            6.0940e-01, -2.5895e-02],\n",
       "          [-3.4347e-01,  4.4713e-01,  3.8172e-01,  7.2989e-01,  6.7500e-01,\n",
       "           -1.9895e-01,  1.1855e-01, -3.5073e-01,  3.3651e-02,  6.1091e-02,\n",
       "           -2.8772e-01, -1.7042e-01]],\n",
       "\n",
       "         [[ 2.2613e-01, -1.3514e-01, -7.1378e-01, -3.9440e-01,  3.8621e-01,\n",
       "            2.7064e-01, -7.5971e-01,  2.6336e-01, -1.0278e-01, -3.0491e-01,\n",
       "            5.4776e-01,  9.6854e-02],\n",
       "          [-9.1671e-01, -1.1677e+00, -2.7255e-01,  9.4297e-01,  9.0114e-02,\n",
       "           -7.1825e-01,  9.6317e-02, -4.6757e-01,  6.1223e-01,  1.9739e-01,\n",
       "            8.8858e-01,  2.2634e-02],\n",
       "          [ 1.1139e-01, -1.2498e-01, -2.3631e-01, -2.0329e-01, -5.2139e-01,\n",
       "           -4.9101e-02, -3.4918e-01,  4.0786e-01,  1.6225e-02, -3.7806e-01,\n",
       "            3.2250e-01, -5.5729e-01],\n",
       "          [-1.7592e-01,  1.0903e-01,  9.4897e-02, -1.5524e-01, -3.1348e-02,\n",
       "           -5.0950e-01, -2.0351e+00, -1.8368e-01, -3.6766e-01, -2.2375e-01,\n",
       "           -4.5252e-01, -7.8393e-02],\n",
       "          [-1.1048e+00, -3.8785e-01, -5.2041e-01, -1.3316e+00, -1.4703e+00,\n",
       "           -1.1069e-01,  1.2371e+00,  1.0195e-01,  4.0253e-01, -1.7396e+00,\n",
       "           -8.4483e-02,  8.6641e-01],\n",
       "          [-1.0320e+00, -8.1376e-01, -5.7143e-01,  4.7374e-01, -1.6981e-01,\n",
       "           -3.6563e-01,  1.1609e+00, -1.2446e-01,  1.2371e-01, -5.5429e-01,\n",
       "           -7.7428e-02,  2.8884e-01],\n",
       "          [-1.4241e+00, -3.8533e-02, -6.1650e-01, -6.6436e-01,  5.0498e-01,\n",
       "            4.7403e-01,  3.4877e-01,  9.0461e-02, -7.5005e-01,  1.9876e-01,\n",
       "            2.1657e-01,  9.3442e-01],\n",
       "          [ 2.7598e-01, -5.7481e-01,  1.9405e-01, -6.3620e-01, -2.0390e-01,\n",
       "           -1.5042e-01, -6.0659e-02, -1.0274e-01,  4.8358e-01,  7.2353e-01,\n",
       "           -9.3476e-01, -1.3071e-01],\n",
       "          [-1.2268e+00,  1.1045e-02,  1.4043e-01, -4.8266e-01,  2.6335e-01,\n",
       "            1.0480e-02,  2.3145e-01, -1.8469e-01,  4.7016e-01,  1.1636e-01,\n",
       "           -4.4678e-02, -5.1580e-01],\n",
       "          [-5.8971e-01,  1.5484e-01,  5.3481e-01,  5.2328e-01, -1.0216e+00,\n",
       "            1.7015e-01, -5.2786e-01,  1.0164e-01, -2.6996e-01, -5.3447e-01,\n",
       "            2.4844e-01, -2.0177e+00],\n",
       "          [ 7.1975e-01, -7.7887e-01, -3.0299e-01, -5.8144e-01,  4.0629e-01,\n",
       "           -2.5518e-02, -3.0024e-01,  6.6894e-01, -2.5332e-01,  9.8646e-01,\n",
       "           -4.1073e-03, -6.3800e-01],\n",
       "          [ 2.1371e-01, -5.8562e-01, -1.3904e+00, -8.6400e-01,  5.3113e-01,\n",
       "           -9.5722e-02,  1.1307e-01, -7.4507e-01, -2.1497e-01,  2.1010e-01,\n",
       "           -7.4109e-01,  6.1568e-02]]]], grad_fn=<MkldnnConvolutionBackward0>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conv=torch.nn.Conv2d(in_channels=3, out_channels=6,kernel_size=5, stride=2, padding=0, dilation=2, groups=1,\n",
    "                     bias=True, padding_mode='zeros')\n",
    "torch_out=Conv(inputs)\n",
    "torch_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ede085e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-6.7205e-01,  6.9666e-01, -5.0877e-01, -3.7890e-02, -2.4523e-01,\n",
       "            8.1609e-02,  4.2619e-01, -9.0766e-01,  3.3815e-01, -5.6090e-01,\n",
       "           -1.0934e-01,  3.2475e-02],\n",
       "          [ 6.2436e-01,  5.6893e-02, -6.0532e-01, -3.9386e-01,  1.5883e-01,\n",
       "            3.4871e-01,  5.1953e-01,  2.8136e-01, -8.8076e-02,  3.3201e-01,\n",
       "           -5.2483e-01, -4.8972e-01],\n",
       "          [ 3.2871e-01,  7.7371e-01,  6.6600e-01, -1.1036e+00,  1.8207e-01,\n",
       "            6.3458e-01, -1.8130e-01,  6.8301e-01, -9.6772e-02,  1.1915e+00,\n",
       "           -8.5092e-01, -7.4201e-02],\n",
       "          [ 1.4339e-01, -3.6058e-02, -9.2370e-02,  7.9441e-01,  7.6643e-01,\n",
       "            9.4264e-01, -6.5509e-01, -2.0474e-01,  1.2391e+00, -8.2072e-01,\n",
       "            9.3929e-01,  1.8113e-01],\n",
       "          [ 4.3519e-01,  1.0018e+00, -1.0260e+00,  7.6188e-01,  7.7489e-02,\n",
       "            8.3154e-01, -1.0570e+00, -1.4593e-01, -6.2887e-01, -6.4637e-02,\n",
       "            2.4616e-01,  5.9856e-01],\n",
       "          [-6.4982e-01,  1.0849e-02,  6.0189e-01, -5.7040e-01, -2.5203e-01,\n",
       "           -2.0859e-01, -7.7486e-02, -3.7664e-01,  7.2038e-01, -9.9650e-01,\n",
       "            5.9358e-01,  4.3492e-01],\n",
       "          [-9.1684e-02, -8.8711e-01,  3.8068e-01,  4.2393e-01, -1.1071e+00,\n",
       "           -1.8169e-01, -3.9336e-02,  4.2578e-01,  8.3067e-01,  1.1307e+00,\n",
       "           -4.5076e-01,  5.9938e-01],\n",
       "          [ 1.3455e+00,  6.7979e-01, -3.5560e-04,  3.8856e-01,  6.4437e-01,\n",
       "           -5.0198e-01, -6.2158e-02, -2.9486e-02, -3.1443e-01, -1.9590e-01,\n",
       "           -6.7346e-01, -5.0313e-01],\n",
       "          [ 8.2777e-01, -6.2951e-01, -6.4754e-01, -8.7086e-01, -5.3620e-01,\n",
       "           -9.6251e-02,  1.2400e-01,  7.4044e-01,  1.2076e-01,  4.6812e-01,\n",
       "           -2.4274e-02,  9.8217e-01],\n",
       "          [ 4.5666e-01,  1.1301e-02,  3.0182e-01, -4.7713e-01,  8.7395e-01,\n",
       "           -5.2379e-01,  4.2323e-01, -1.1894e-01, -6.9544e-02, -1.4574e-01,\n",
       "           -5.8335e-01,  7.3448e-01],\n",
       "          [-4.3563e-01, -1.1726e+00, -2.8136e-01,  8.4946e-01,  4.5537e-01,\n",
       "           -4.4767e-01,  1.9758e-01, -1.6297e-01,  6.5518e-01, -3.2415e-01,\n",
       "           -3.6094e-01,  3.6618e-01],\n",
       "          [ 2.7700e-01,  2.6507e-01, -4.3787e-01, -1.0058e+00,  4.7446e-03,\n",
       "           -1.5085e-01, -4.9257e-01, -2.0462e-01, -6.3814e-01,  9.6976e-02,\n",
       "           -3.8779e-01,  7.3469e-01]],\n",
       "\n",
       "         [[-7.3027e-01, -5.0367e-01, -1.5592e-01,  5.7988e-01,  5.7776e-02,\n",
       "           -1.2765e-01,  3.5176e-01, -5.7586e-01, -1.2417e-01, -5.2011e-01,\n",
       "            3.3253e-01,  3.4006e-01],\n",
       "          [ 2.4551e-01, -2.1510e-01,  6.6515e-01, -3.9399e-02,  1.4283e-02,\n",
       "           -4.7614e-01, -1.1327e-01, -2.1384e-01,  1.7876e-01, -6.1574e-02,\n",
       "            2.9337e-01,  8.1531e-01],\n",
       "          [-3.5541e-01, -2.8772e-01, -1.2357e-02, -2.3044e-01,  1.1645e+00,\n",
       "            1.1554e-02, -7.4208e-01, -4.7930e-01,  7.9665e-01, -2.3027e-01,\n",
       "           -6.3339e-01,  1.2518e+00],\n",
       "          [-1.4444e+00,  6.4645e-01, -1.7899e-01,  1.6629e-01, -3.2701e-01,\n",
       "            2.8914e-01, -8.6963e-01,  1.2605e-01,  9.6556e-01, -8.3523e-01,\n",
       "           -4.3442e-01,  7.3513e-01],\n",
       "          [-6.4711e-01, -5.5644e-01,  2.3915e-01, -4.2356e-01, -1.2149e+00,\n",
       "           -6.2686e-01,  1.1744e-01, -2.8294e-02, -2.3188e-02, -1.1136e+00,\n",
       "           -3.9178e-01, -1.2112e-01],\n",
       "          [ 8.2422e-02, -1.3503e+00,  1.9820e-01, -1.5923e-01,  2.9376e-01,\n",
       "           -2.9506e-01, -5.7527e-01,  6.3136e-02, -2.0237e-01,  1.0645e+00,\n",
       "           -7.0299e-01, -3.2713e-02],\n",
       "          [-2.9012e-01, -4.2412e-01, -4.0330e-01, -9.0063e-01,  3.5605e-01,\n",
       "           -2.5438e-01,  1.4967e+00,  2.0378e-02, -4.8262e-01, -2.0645e-01,\n",
       "           -4.9091e-01, -5.2497e-01],\n",
       "          [-6.2565e-02,  9.5195e-02,  1.9944e-02,  8.2481e-01,  5.4993e-01,\n",
       "           -9.8231e-01, -2.2754e-01,  1.5423e-01, -1.5635e-01,  7.7450e-01,\n",
       "            8.1970e-01, -3.8472e-01],\n",
       "          [ 8.6040e-02, -4.7582e-01, -3.0575e-01, -2.4865e-01,  1.0841e-02,\n",
       "            4.0910e-01,  2.5189e-01,  2.0973e-01, -3.3921e-01,  3.5835e-02,\n",
       "            9.6505e-01, -5.1768e-01],\n",
       "          [-5.2470e-01, -5.3361e-02, -7.4604e-01,  3.7049e-02, -8.0600e-02,\n",
       "            2.5469e-01,  4.1170e-02,  2.2930e-01, -3.3408e-01,  4.0434e-01,\n",
       "            5.1574e-01, -1.1893e-01],\n",
       "          [ 2.4161e-01,  4.5966e-01,  3.2727e-02,  2.6945e-01, -4.2059e-02,\n",
       "           -1.4860e-02,  4.5440e-01, -1.5424e-01,  8.4496e-01,  1.6328e-01,\n",
       "            8.3489e-02,  1.1615e-01],\n",
       "          [-4.5997e-01,  1.1552e-01,  1.0303e+00, -2.9112e-02, -1.3089e+00,\n",
       "            3.2998e-01,  3.4280e-01, -4.4130e-02,  2.3310e-01, -4.9691e-01,\n",
       "            6.8717e-01, -7.9400e-02]],\n",
       "\n",
       "         [[-5.2890e-01, -6.5919e-01, -8.1335e-02,  1.6073e-01,  2.2464e-01,\n",
       "            6.9639e-01,  2.6958e-01,  7.0962e-03, -2.1184e-02,  3.6287e-01,\n",
       "           -5.2197e-01,  2.3983e-02],\n",
       "          [ 1.5726e-01,  1.2720e-01, -1.2707e-01, -2.7525e-01, -1.0884e+00,\n",
       "           -2.6033e-01, -1.2029e+00, -1.9073e-01, -6.6164e-01, -9.2987e-01,\n",
       "           -3.8076e-01, -8.7490e-01],\n",
       "          [-2.3429e-01, -1.9576e-02, -5.6148e-01, -6.9825e-02, -1.9858e-01,\n",
       "            1.9136e-01, -2.4608e-01,  4.4442e-01,  3.5514e-01, -2.9468e-01,\n",
       "           -4.2092e-01,  1.4033e+00],\n",
       "          [ 3.1741e-01,  9.0054e-01,  3.5665e-01,  1.7085e-01,  1.3658e-01,\n",
       "           -2.2635e-01,  3.0685e-01,  3.1527e-02,  1.3652e+00, -5.0263e-01,\n",
       "            1.0076e+00,  6.3959e-01],\n",
       "          [-1.1465e+00,  2.3481e-01,  4.3839e-01,  5.1311e-01,  1.8746e+00,\n",
       "            1.0591e+00,  3.2788e-01,  1.0474e+00, -5.0655e-01,  5.2533e-02,\n",
       "           -1.1782e+00,  1.4025e+00],\n",
       "          [-2.5618e-02, -8.5647e-01,  4.5521e-01, -3.9049e-01,  1.2038e-01,\n",
       "           -1.3919e-03, -1.1128e-03, -2.7469e-01,  1.0433e+00,  1.3070e+00,\n",
       "            1.5187e+00, -7.3346e-01],\n",
       "          [-4.8669e-01, -5.8018e-02,  5.4785e-01,  3.5187e-01, -1.1113e+00,\n",
       "           -6.4756e-01, -6.3405e-02,  6.5448e-01,  1.2834e-01,  9.0212e-01,\n",
       "           -5.2198e-01, -1.2562e+00],\n",
       "          [-5.6363e-02, -9.8644e-01, -1.2900e+00, -5.8888e-01, -1.5661e-01,\n",
       "           -6.0439e-01, -6.0571e-02, -1.6543e-01, -8.2090e-03,  1.8829e-02,\n",
       "            5.3089e-01, -5.5485e-01],\n",
       "          [ 8.2295e-01,  5.8250e-01, -4.3053e-03, -3.1922e-01, -1.5907e-01,\n",
       "           -3.8588e-01,  4.1583e-01,  7.5387e-01, -6.7102e-01, -1.2800e+00,\n",
       "           -7.3912e-01,  5.3400e-01],\n",
       "          [-5.5000e-01,  3.6235e-01, -1.8693e-01, -4.0040e-01,  2.1038e-01,\n",
       "           -4.1223e-02,  5.2913e-01, -1.8546e-01, -3.8950e-01,  1.5718e-01,\n",
       "            2.7970e-01,  1.2704e+00],\n",
       "          [-3.8298e-01, -5.4841e-02, -6.1076e-01, -6.1446e-02,  2.1672e-01,\n",
       "            7.6985e-01, -1.1245e+00, -7.0782e-01, -1.1157e+00, -1.1985e-01,\n",
       "           -9.4216e-01, -1.2835e+00],\n",
       "          [-2.5544e-01, -1.1441e+00,  1.6443e-01,  1.8261e-02, -4.9279e-01,\n",
       "            3.8021e-01,  5.9442e-01, -7.5210e-01, -8.1439e-01, -8.9056e-01,\n",
       "           -5.7925e-01,  3.1479e-01]],\n",
       "\n",
       "         [[ 2.5376e-02,  1.6319e-01,  6.2676e-01, -2.0871e-01, -1.6124e-01,\n",
       "            5.1404e-01,  1.0051e-01,  1.5059e-02,  4.8149e-02,  8.9085e-02,\n",
       "           -1.8993e-01, -1.6063e-01],\n",
       "          [ 6.2120e-01,  6.6639e-01, -3.4460e-01, -1.3055e-01,  5.3895e-01,\n",
       "            6.6212e-01,  1.1427e-01, -3.2113e-01,  8.9850e-01, -1.7020e-01,\n",
       "           -8.1887e-01,  3.5111e-01],\n",
       "          [ 7.6722e-01,  5.0662e-02, -6.7168e-01,  1.4285e-01,  4.0315e-01,\n",
       "           -4.2597e-03, -1.1956e+00,  6.0848e-01, -9.0894e-01, -6.1425e-01,\n",
       "           -8.4676e-01, -5.5761e-01],\n",
       "          [ 1.2619e-01, -3.2555e-02,  4.3544e-01,  5.4264e-01,  6.1410e-02,\n",
       "            1.4392e-01, -3.6162e-02, -9.5187e-01, -5.0276e-01, -4.9537e-01,\n",
       "            2.3754e-01,  7.6488e-01],\n",
       "          [ 1.1462e+00, -2.0496e-02, -1.9182e-01, -2.2034e-01,  1.6565e-01,\n",
       "            1.8566e-01,  9.0330e-01,  1.2145e+00, -2.2098e-01,  7.4620e-01,\n",
       "            7.0384e-01, -3.4788e-01],\n",
       "          [ 1.9464e-01, -6.7792e-01,  9.9185e-01, -2.5504e-01,  4.8866e-01,\n",
       "            1.1880e-01, -1.8642e-02,  4.7043e-02,  7.8961e-01,  4.3810e-01,\n",
       "           -1.4464e-01, -1.7526e-01],\n",
       "          [ 1.1247e+00, -8.2698e-01,  7.6209e-02,  5.8359e-01, -7.9799e-01,\n",
       "           -5.0766e-01, -3.0304e-01,  4.9187e-01, -4.2979e-01,  1.3753e+00,\n",
       "            3.3792e-02, -1.0070e+00],\n",
       "          [ 2.2769e-02, -7.6632e-01,  4.4662e-01, -2.3391e-01,  4.0546e-01,\n",
       "            8.1425e-01,  4.8306e-01,  1.5078e-01,  1.5743e-01,  9.4850e-04,\n",
       "            4.0271e-01, -3.6037e-01],\n",
       "          [ 1.1191e-01, -7.4004e-01, -6.2128e-03, -2.4848e-01, -2.1454e-01,\n",
       "           -6.8261e-01,  7.7674e-02,  7.5046e-01,  6.7679e-01, -9.2583e-02,\n",
       "            1.2608e+00,  1.6597e-01],\n",
       "          [-4.5190e-01, -8.0746e-01, -5.6925e-01, -3.8100e-01,  5.8905e-01,\n",
       "            5.0404e-01,  4.0713e-01, -4.8072e-01,  3.0190e-01,  6.9355e-02,\n",
       "            1.5715e+00,  8.3933e-01],\n",
       "          [-8.7551e-02,  1.0417e+00,  2.4482e-01, -1.4599e-01,  8.4179e-02,\n",
       "            6.7651e-01,  5.7687e-01,  3.5772e-01,  4.5739e-01,  9.8245e-01,\n",
       "            4.8280e-01,  3.9436e-01],\n",
       "          [ 4.1457e-01,  7.5537e-01, -1.8520e-01, -6.6901e-01, -3.0914e-01,\n",
       "            9.1653e-01, -1.4656e-01,  2.8563e-02, -7.2327e-01, -9.0261e-02,\n",
       "           -1.1129e+00, -9.1251e-02]],\n",
       "\n",
       "         [[ 1.8803e-01,  2.1684e-01,  9.8001e-01, -8.2652e-01,  1.0779e-01,\n",
       "            7.6894e-01,  1.1247e-01, -4.0833e-01,  3.7630e-02,  4.9627e-01,\n",
       "           -3.1204e-01,  8.6397e-01],\n",
       "          [-6.5819e-01,  4.4563e-01,  4.0588e-01, -5.7009e-01,  1.0498e+00,\n",
       "            6.9169e-01, -5.4973e-01, -1.5273e-01,  6.6583e-01, -8.9778e-01,\n",
       "           -3.5812e-01,  9.8160e-01],\n",
       "          [ 4.9277e-01,  1.5016e-01, -7.4315e-01, -2.1890e-01,  4.8781e-01,\n",
       "            3.9351e-01, -4.9634e-01,  5.2443e-01,  7.1662e-01, -7.4248e-01,\n",
       "            4.3938e-02,  6.8254e-02],\n",
       "          [ 5.3476e-01, -3.6549e-02,  1.3523e-01,  2.5943e-01,  3.8502e-01,\n",
       "            4.7982e-02, -1.6184e-01,  3.4961e-01,  7.8778e-02,  7.5478e-01,\n",
       "            8.7988e-01,  4.2299e-01],\n",
       "          [-2.0653e-01, -1.1936e+00,  6.8872e-02, -9.4410e-02,  4.9724e-02,\n",
       "            2.7211e-01, -7.5674e-02, -9.1852e-01, -3.9042e-01,  3.4857e-01,\n",
       "           -3.1167e-01, -5.4956e-01],\n",
       "          [ 5.1748e-02,  2.6464e-01, -9.1605e-01,  2.1229e-01,  8.9247e-01,\n",
       "           -7.2642e-01, -1.8022e-01, -7.1954e-01, -1.4874e-01,  4.7678e-01,\n",
       "            2.0320e-01,  3.8618e-01],\n",
       "          [-2.4740e-02,  4.8828e-01, -2.8796e-02, -5.1224e-01, -9.9737e-01,\n",
       "            1.5050e-01,  1.2172e+00,  3.6795e-01, -1.3390e-01,  6.0861e-01,\n",
       "           -1.7307e-01, -6.1473e-01],\n",
       "          [-3.2213e-01, -3.1331e-02,  6.3303e-01,  1.1299e+00,  6.0478e-01,\n",
       "            2.9558e-01,  7.0055e-01,  5.3214e-01, -4.3844e-01, -4.8836e-01,\n",
       "           -1.0033e+00, -8.2306e-02],\n",
       "          [-3.0873e-02,  5.3930e-01, -3.1767e-01,  3.1546e-01, -1.9717e-02,\n",
       "            4.2696e-01, -3.8256e-03, -3.5957e-01,  5.2971e-01,  1.7726e-01,\n",
       "            2.1046e-01,  1.6542e-02],\n",
       "          [-3.7197e-01, -5.1100e-02,  4.2823e-01,  3.0525e-01, -3.7989e-01,\n",
       "            6.5999e-01,  8.9861e-01,  3.7551e-01, -3.2365e-02, -6.2269e-01,\n",
       "            4.7986e-01, -1.8032e-01],\n",
       "          [-2.7058e-01,  6.5943e-01,  5.4721e-01, -3.6574e-01, -4.5872e-01,\n",
       "            4.7253e-01, -1.4386e-01,  1.0522e+00, -6.7757e-02,  2.3113e-01,\n",
       "            6.0940e-01, -2.5895e-02],\n",
       "          [-3.4347e-01,  4.4713e-01,  3.8172e-01,  7.2989e-01,  6.7500e-01,\n",
       "           -1.9895e-01,  1.1855e-01, -3.5073e-01,  3.3651e-02,  6.1091e-02,\n",
       "           -2.8772e-01, -1.7042e-01]],\n",
       "\n",
       "         [[ 2.2613e-01, -1.3514e-01, -7.1378e-01, -3.9440e-01,  3.8621e-01,\n",
       "            2.7064e-01, -7.5971e-01,  2.6336e-01, -1.0278e-01, -3.0491e-01,\n",
       "            5.4776e-01,  9.6854e-02],\n",
       "          [-9.1671e-01, -1.1677e+00, -2.7255e-01,  9.4297e-01,  9.0114e-02,\n",
       "           -7.1825e-01,  9.6317e-02, -4.6757e-01,  6.1223e-01,  1.9739e-01,\n",
       "            8.8858e-01,  2.2634e-02],\n",
       "          [ 1.1139e-01, -1.2498e-01, -2.3631e-01, -2.0329e-01, -5.2139e-01,\n",
       "           -4.9101e-02, -3.4918e-01,  4.0786e-01,  1.6225e-02, -3.7806e-01,\n",
       "            3.2250e-01, -5.5729e-01],\n",
       "          [-1.7592e-01,  1.0903e-01,  9.4897e-02, -1.5524e-01, -3.1348e-02,\n",
       "           -5.0950e-01, -2.0351e+00, -1.8368e-01, -3.6766e-01, -2.2375e-01,\n",
       "           -4.5252e-01, -7.8393e-02],\n",
       "          [-1.1048e+00, -3.8785e-01, -5.2041e-01, -1.3316e+00, -1.4703e+00,\n",
       "           -1.1069e-01,  1.2371e+00,  1.0195e-01,  4.0253e-01, -1.7396e+00,\n",
       "           -8.4483e-02,  8.6641e-01],\n",
       "          [-1.0320e+00, -8.1376e-01, -5.7143e-01,  4.7374e-01, -1.6981e-01,\n",
       "           -3.6563e-01,  1.1609e+00, -1.2446e-01,  1.2371e-01, -5.5429e-01,\n",
       "           -7.7428e-02,  2.8884e-01],\n",
       "          [-1.4241e+00, -3.8533e-02, -6.1650e-01, -6.6436e-01,  5.0498e-01,\n",
       "            4.7403e-01,  3.4877e-01,  9.0461e-02, -7.5005e-01,  1.9876e-01,\n",
       "            2.1657e-01,  9.3442e-01],\n",
       "          [ 2.7598e-01, -5.7481e-01,  1.9405e-01, -6.3620e-01, -2.0390e-01,\n",
       "           -1.5042e-01, -6.0659e-02, -1.0274e-01,  4.8358e-01,  7.2353e-01,\n",
       "           -9.3476e-01, -1.3071e-01],\n",
       "          [-1.2268e+00,  1.1045e-02,  1.4043e-01, -4.8266e-01,  2.6335e-01,\n",
       "            1.0480e-02,  2.3145e-01, -1.8469e-01,  4.7016e-01,  1.1636e-01,\n",
       "           -4.4678e-02, -5.1580e-01],\n",
       "          [-5.8971e-01,  1.5484e-01,  5.3481e-01,  5.2328e-01, -1.0216e+00,\n",
       "            1.7015e-01, -5.2786e-01,  1.0164e-01, -2.6996e-01, -5.3447e-01,\n",
       "            2.4844e-01, -2.0177e+00],\n",
       "          [ 7.1975e-01, -7.7887e-01, -3.0299e-01, -5.8144e-01,  4.0629e-01,\n",
       "           -2.5517e-02, -3.0024e-01,  6.6894e-01, -2.5332e-01,  9.8646e-01,\n",
       "           -4.1072e-03, -6.3800e-01],\n",
       "          [ 2.1371e-01, -5.8562e-01, -1.3904e+00, -8.6400e-01,  5.3113e-01,\n",
       "           -9.5722e-02,  1.1307e-01, -7.4507e-01, -2.1497e-01,  2.1010e-01,\n",
       "           -7.4109e-01,  6.1568e-02]]]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernels = Conv.weight.data\n",
    "bias = Conv.bias.data\n",
    "\n",
    "def one_kernel_dilation(kernel, dilation):\n",
    "    dilation_kernel = torch.zeros([len(kernel)+(dilation-1)*(len(kernel)-1), len(kernel)+(dilation-1)*(len(kernel)-1)])\n",
    "    count = 0\n",
    "    for i in range(0, len(dilation_kernel), dilation):\n",
    "        for j in range(0, len(dilation_kernel), dilation):\n",
    "            dilation_kernel[i][j] = kernel.flatten()[count]\n",
    "            count+=1\n",
    "    return dilation_kernel\n",
    "\n",
    "def all_kernel_dilation(kernel, dilation):\n",
    "    kernels = torch.zeros([len(kernel), len(kernel[0]), len(kernel[0][0])+(dilation-1)*(len(kernel[0][0])-1), len(kernel[0][0])+(dilation-1)*(len(kernel[0][0])-1)])\n",
    "    for i in range(len(kernel)):\n",
    "        for j in range(len(kernel[0])):\n",
    "            kernels[i][j] = one_kernel_dilation(kernel[i][j], dilation)\n",
    "    return kernels\n",
    "\n",
    "def convolution2D(inputs, kernel, bias, stride, dilation):\n",
    "    if dilation != 1:\n",
    "        kernels = all_kernel_dilation(kernel, dilation=dilation)\n",
    "    out = conv2d(inputs, kernels, bias, stride)\n",
    "    return out\n",
    "\n",
    "# test multi channel and multi kernel\n",
    "\n",
    "my_out = convolution2D(inputs, kernels, bias, 2, 2)\n",
    "my_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "31560fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True]],\n",
       "\n",
       "         [[True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True]],\n",
       "\n",
       "         [[True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True]],\n",
       "\n",
       "         [[True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True]],\n",
       "\n",
       "         [[True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True]],\n",
       "\n",
       "         [[True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True]]]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_out - my_out<=0.000001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcbb6fb",
   "metadata": {},
   "source": [
    "# Conv2D Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "df725ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.3891e-01,  2.1060e-01, -1.8841e-01,  ...,  3.0564e-01,\n",
       "            1.4281e-02, -3.8213e-02],\n",
       "          [ 2.2454e-01,  1.4816e-01,  4.4866e-02,  ..., -4.9636e-01,\n",
       "           -4.8723e-02,  1.3326e-01],\n",
       "          [-2.0076e-01, -3.8757e-01, -2.1847e-01,  ..., -6.6750e-01,\n",
       "           -4.0777e-01, -1.5830e-02],\n",
       "          ...,\n",
       "          [-1.9467e-01,  8.4558e-01, -2.4026e-01,  ...,  9.3834e-02,\n",
       "           -2.2740e-01, -1.4756e-01],\n",
       "          [-3.8045e-01,  7.6494e-01, -9.1256e-01,  ..., -7.7247e-01,\n",
       "            1.0374e-01, -1.1644e-02],\n",
       "          [-1.4653e-01, -1.7017e-01, -2.7070e-01,  ..., -2.1440e-01,\n",
       "            2.6342e-01, -9.4709e-02]],\n",
       "\n",
       "         [[-1.5969e-01,  8.3216e-02,  4.5905e-02,  ...,  2.2385e-02,\n",
       "           -2.4490e-01,  2.9391e-01],\n",
       "          [-1.9731e-02,  3.6226e-01, -7.7498e-04,  ..., -1.9056e-01,\n",
       "            1.2951e-01,  2.3212e-01],\n",
       "          [-3.5382e-01,  1.9782e-01, -4.3353e-01,  ..., -6.0119e-01,\n",
       "           -1.2725e-01, -4.8110e-02],\n",
       "          ...,\n",
       "          [-1.2366e-01, -1.5810e-01,  4.3316e-01,  ...,  7.8904e-02,\n",
       "           -2.4234e-01, -1.0320e-02],\n",
       "          [-3.2949e-02, -2.6789e-01, -2.6217e-01,  ..., -2.8753e-01,\n",
       "            1.6144e-01,  1.3876e-01],\n",
       "          [-1.8136e-01, -5.6614e-02, -8.4933e-02,  ...,  3.1487e-01,\n",
       "            4.9516e-01,  9.5783e-02]],\n",
       "\n",
       "         [[-1.9178e-01, -4.0571e-02, -2.0730e-01,  ..., -1.1357e-01,\n",
       "           -2.2528e-01,  5.3931e-02],\n",
       "          [-2.1103e-01,  1.6799e-02, -1.4580e-01,  ...,  1.9941e-01,\n",
       "           -4.0250e-01,  1.3397e-01],\n",
       "          [-3.3629e-01,  7.9692e-02, -1.9506e-01,  ...,  4.3489e-01,\n",
       "            1.3753e-01, -2.6469e-01],\n",
       "          ...,\n",
       "          [-1.4138e-02,  4.1896e-02, -8.6416e-01,  ..., -3.6302e-01,\n",
       "           -6.5335e-01,  3.3757e-01],\n",
       "          [ 2.6284e-01, -1.5569e-01, -7.5206e-01,  ..., -4.9955e-01,\n",
       "           -2.2589e-01, -5.3652e-01],\n",
       "          [-1.3873e-02, -3.0903e-01, -3.9369e-01,  ...,  6.4281e-02,\n",
       "            3.5335e-01, -2.7782e-01]],\n",
       "\n",
       "         [[ 3.0258e-01, -1.5967e-01,  5.2093e-02,  ...,  3.2904e-02,\n",
       "           -2.1693e-01,  3.3160e-01],\n",
       "          [ 4.3141e-01,  3.1320e-01,  5.2509e-01,  ...,  6.6187e-01,\n",
       "           -5.2165e-01,  4.5692e-01],\n",
       "          [ 1.2969e-01, -1.1574e-01,  2.8692e-01,  ...,  3.2980e-01,\n",
       "           -3.3638e-01,  3.3777e-01],\n",
       "          ...,\n",
       "          [ 1.2519e+00, -6.5762e-01,  1.2967e+00,  ...,  6.6570e-01,\n",
       "           -3.4161e-01,  4.3251e-01],\n",
       "          [ 6.3226e-02,  1.8257e-01,  2.2205e-01,  ...,  4.5223e-01,\n",
       "           -9.6949e-02,  3.4170e-01],\n",
       "          [-1.8444e-01,  4.9099e-03, -2.3028e-02,  ...,  5.8416e-02,\n",
       "            4.9035e-01, -2.4062e-01]]]],\n",
       "       grad_fn=<SlowConvTranspose2DBackward0>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConvTranspose = torch.nn.ConvTranspose2d(in_channels=3, out_channels=4,kernel_size=3, stride=1, padding=0, output_padding=0,\n",
    "groups=1, bias=True, dilation=1, padding_mode='zeros')\n",
    "torch_out=ConvTranspose(inputs)\n",
    "torch_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b245df7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.3891e-01,  2.1060e-01, -1.8841e-01,  ...,  3.0564e-01,\n",
       "            1.4281e-02, -3.8213e-02],\n",
       "          [ 2.2454e-01,  1.4816e-01,  4.4866e-02,  ..., -4.9636e-01,\n",
       "           -4.8723e-02,  1.3326e-01],\n",
       "          [-2.0076e-01, -3.8757e-01, -2.1847e-01,  ..., -6.6750e-01,\n",
       "           -4.0777e-01, -1.5830e-02],\n",
       "          ...,\n",
       "          [-1.9467e-01,  8.4558e-01, -2.4026e-01,  ...,  9.3834e-02,\n",
       "           -2.2740e-01, -1.4756e-01],\n",
       "          [-3.8045e-01,  7.6494e-01, -9.1256e-01,  ..., -7.7247e-01,\n",
       "            1.0374e-01, -1.1644e-02],\n",
       "          [-1.4653e-01, -1.7017e-01, -2.7070e-01,  ..., -2.1440e-01,\n",
       "            2.6342e-01, -9.4709e-02]],\n",
       "\n",
       "         [[-1.5969e-01,  8.3216e-02,  4.5905e-02,  ...,  2.2385e-02,\n",
       "           -2.4490e-01,  2.9391e-01],\n",
       "          [-1.9731e-02,  3.6226e-01, -7.7501e-04,  ..., -1.9056e-01,\n",
       "            1.2951e-01,  2.3212e-01],\n",
       "          [-3.5382e-01,  1.9782e-01, -4.3353e-01,  ..., -6.0119e-01,\n",
       "           -1.2725e-01, -4.8110e-02],\n",
       "          ...,\n",
       "          [-1.2366e-01, -1.5810e-01,  4.3316e-01,  ...,  7.8904e-02,\n",
       "           -2.4234e-01, -1.0320e-02],\n",
       "          [-3.2949e-02, -2.6789e-01, -2.6217e-01,  ..., -2.8753e-01,\n",
       "            1.6144e-01,  1.3876e-01],\n",
       "          [-1.8136e-01, -5.6614e-02, -8.4933e-02,  ...,  3.1487e-01,\n",
       "            4.9516e-01,  9.5783e-02]],\n",
       "\n",
       "         [[-1.9178e-01, -4.0571e-02, -2.0730e-01,  ..., -1.1357e-01,\n",
       "           -2.2528e-01,  5.3931e-02],\n",
       "          [-2.1103e-01,  1.6799e-02, -1.4580e-01,  ...,  1.9941e-01,\n",
       "           -4.0250e-01,  1.3397e-01],\n",
       "          [-3.3629e-01,  7.9692e-02, -1.9506e-01,  ...,  4.3489e-01,\n",
       "            1.3753e-01, -2.6469e-01],\n",
       "          ...,\n",
       "          [-1.4138e-02,  4.1896e-02, -8.6416e-01,  ..., -3.6302e-01,\n",
       "           -6.5335e-01,  3.3757e-01],\n",
       "          [ 2.6284e-01, -1.5569e-01, -7.5206e-01,  ..., -4.9955e-01,\n",
       "           -2.2589e-01, -5.3652e-01],\n",
       "          [-1.3873e-02, -3.0903e-01, -3.9369e-01,  ...,  6.4281e-02,\n",
       "            3.5335e-01, -2.7782e-01]],\n",
       "\n",
       "         [[ 3.0258e-01, -1.5967e-01,  5.2093e-02,  ...,  3.2904e-02,\n",
       "           -2.1693e-01,  3.3160e-01],\n",
       "          [ 4.3141e-01,  3.1320e-01,  5.2509e-01,  ...,  6.6187e-01,\n",
       "           -5.2165e-01,  4.5692e-01],\n",
       "          [ 1.2969e-01, -1.1574e-01,  2.8692e-01,  ...,  3.2980e-01,\n",
       "           -3.3638e-01,  3.3777e-01],\n",
       "          ...,\n",
       "          [ 1.2519e+00, -6.5762e-01,  1.2967e+00,  ...,  6.6570e-01,\n",
       "           -3.4161e-01,  4.3251e-01],\n",
       "          [ 6.3226e-02,  1.8257e-01,  2.2205e-01,  ...,  4.5223e-01,\n",
       "           -9.6949e-02,  3.4170e-01],\n",
       "          [-1.8444e-01,  4.9099e-03, -2.3028e-02,  ...,  5.8416e-02,\n",
       "            4.9035e-01, -2.4062e-01]]]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = ConvTranspose.weight.data\n",
    "bias = ConvTranspose.bias.data\n",
    "def transpose_conv(inputs, weight, bias):\n",
    "    in_, out_, H, W = weight.shape\n",
    "    out = torch.zeros(1, out_, inputs.shape[2]+H-1, inputs.shape[3]+W-1)\n",
    "    for batch in range(1):\n",
    "        for out_channel in range(out_):\n",
    "            for in_channel in range(in_):\n",
    "                for row in range(inputs.shape[2]):\n",
    "                    for col in range(inputs.shape[3]):\n",
    "                        out[batch, out_channel, row:row+H, col:col+W] += inputs[batch, in_channel, row, col] * weight[in_channel,out_channel,:,:]\n",
    "            out[batch,out_channel,:,:] +=bias[out_channel]\n",
    "    return out                                             \n",
    "my_out = transpose_conv(inputs, weight, bias)\n",
    "my_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "32bee952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_out - my_out<=0.000001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd3c49c",
   "metadata": {},
   "source": [
    "#  Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7a891214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.1258398 , -1.1523602 , -0.25057858, ..., -0.6380098 ,\n",
       "       -1.1713753 , -0.8415489 ], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_out = torch.flatten(inputs, start_dim=0, end_dim=-1)\n",
    "torch_out = torch_out.numpy()\n",
    "torch_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3019cdb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.1258398 , -1.1523602 , -0.25057858, ..., -0.6380098 ,\n",
       "       -1.1713753 , -0.8415489 ], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_out = input_np.flatten()\n",
    "my_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1b210dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_out == my_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a5d169",
   "metadata": {},
   "source": [
    "#  Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "75822646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.2449, 0.2401, 0.4377, ..., 0.8301, 0.7204, 0.3008],\n",
       "         [0.3512, 0.5079, 0.3793, ..., 0.2255, 0.8605, 0.3655],\n",
       "         [0.3614, 0.715 , 0.7523, ..., 0.2776, 0.5084, 0.6704],\n",
       "         ...,\n",
       "         [0.7343, 0.7836, 0.8891, ..., 0.6934, 0.361 , 0.4702],\n",
       "         [0.3948, 0.693 , 0.1959, ..., 0.4652, 0.4091, 0.3876],\n",
       "         [0.2151, 0.6685, 0.129 , ..., 0.6312, 0.747 , 0.1531]],\n",
       "\n",
       "        [[0.2527, 0.4679, 0.336 , ..., 0.2724, 0.6723, 0.6083],\n",
       "         [0.3631, 0.6601, 0.1088, ..., 0.3139, 0.1052, 0.5827],\n",
       "         [0.2455, 0.6504, 0.2939, ..., 0.7142, 0.5742, 0.5442],\n",
       "         ...,\n",
       "         [0.9068, 0.2866, 0.6249, ..., 0.6195, 0.2836, 0.3601],\n",
       "         [0.6748, 0.2832, 0.5435, ..., 0.3302, 0.2929, 0.3567],\n",
       "         [0.3023, 0.1376, 0.6169, ..., 0.4058, 0.1586, 0.7478]],\n",
       "\n",
       "        [[0.6605, 0.7078, 0.6147, ..., 0.6837, 0.3012, 0.8577],\n",
       "         [0.5479, 0.4557, 0.5797, ..., 0.2384, 0.3562, 0.6782],\n",
       "         [0.2338, 0.3053, 0.6468, ..., 0.4525, 0.5625, 0.7948],\n",
       "         ...,\n",
       "         [0.8735, 0.3583, 0.2121, ..., 0.5713, 0.5651, 0.4114],\n",
       "         [0.9449, 0.3452, 0.3572, ..., 0.6223, 0.1736, 0.7561],\n",
       "         [0.4874, 0.6337, 0.2253, ..., 0.3457, 0.2366, 0.3012]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_out = torch.sigmoid(inputs,  out=None)\n",
    "torch_out = torch_out.numpy()\n",
    "torch_out = np.around(torch_out, decimals=4, out=None)\n",
    "torch_out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b66ba2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.2449, 0.2401, 0.4377, ..., 0.8301, 0.7204, 0.3008],\n",
       "         [0.3512, 0.5079, 0.3793, ..., 0.2255, 0.8605, 0.3655],\n",
       "         [0.3614, 0.715 , 0.7523, ..., 0.2776, 0.5084, 0.6704],\n",
       "         ...,\n",
       "         [0.7343, 0.7836, 0.8891, ..., 0.6934, 0.361 , 0.4702],\n",
       "         [0.3948, 0.693 , 0.1959, ..., 0.4652, 0.4091, 0.3876],\n",
       "         [0.2151, 0.6685, 0.129 , ..., 0.6312, 0.747 , 0.1531]],\n",
       "\n",
       "        [[0.2527, 0.4679, 0.336 , ..., 0.2724, 0.6723, 0.6083],\n",
       "         [0.3631, 0.6601, 0.1088, ..., 0.3139, 0.1052, 0.5827],\n",
       "         [0.2455, 0.6504, 0.2939, ..., 0.7142, 0.5742, 0.5442],\n",
       "         ...,\n",
       "         [0.9068, 0.2866, 0.6249, ..., 0.6195, 0.2836, 0.3601],\n",
       "         [0.6748, 0.2832, 0.5435, ..., 0.3302, 0.2929, 0.3567],\n",
       "         [0.3023, 0.1376, 0.6169, ..., 0.4058, 0.1586, 0.7478]],\n",
       "\n",
       "        [[0.6605, 0.7078, 0.6147, ..., 0.6837, 0.3012, 0.8577],\n",
       "         [0.5479, 0.4557, 0.5797, ..., 0.2384, 0.3562, 0.6782],\n",
       "         [0.2338, 0.3053, 0.6468, ..., 0.4525, 0.5625, 0.7948],\n",
       "         ...,\n",
       "         [0.8735, 0.3583, 0.2121, ..., 0.5713, 0.5651, 0.4114],\n",
       "         [0.9449, 0.3452, 0.3572, ..., 0.6223, 0.1736, 0.7561],\n",
       "         [0.4874, 0.6337, 0.2253, ..., 0.3457, 0.2366, 0.3012]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "        return 1.0/(1+np.exp(-x))\n",
    "my_out = input_np\n",
    "my_out = sigmoid(my_out)\n",
    "my_out = np.around(my_out, decimals=4, out=None)\n",
    "my_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "af440b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]]]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_out == my_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b01fe7",
   "metadata": {},
   "source": [
    "#  ROI pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e31524f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1.645867 ]],\n",
       "\n",
       "        [[0.8777172]],\n",
       "\n",
       "        [[1.8793321]]]], dtype=float32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rois_in_feature = torch.Tensor([[0, 0, 0, 3, 3]])\n",
    "import torchvision\n",
    "torch_out =torchvision.ops.roi_pool(input = inputs,  boxes=rois_in_feature, output_size = 1,spatial_scale = 1.0)\n",
    "torch_out = torch_out.numpy()\n",
    "torch_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54e1f75",
   "metadata": {},
   "source": [
    "\n",
    "    param feature_map: (1, C, H, W)\n",
    "    param rois: (1, N, 4) N refers to bbox num, 4 represent (ltx, lty, w, h) \n",
    "    param size: output size\n",
    "    return: (1, C, size[0], size[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4b52a0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[[1.64586699]],\n",
      "\n",
      "        [[0.8777172 ]],\n",
      "\n",
      "        [[1.87933207]]]])]\n"
     ]
    }
   ],
   "source": [
    "def roi_pooling(feature_map, rois, size=(1, 1)):\n",
    "    \n",
    "    output = []\n",
    "    rois_num = rois.size(1)\n",
    "\n",
    "    for i in range(rois_num):\n",
    "        roi = rois[0][i]\n",
    "        x, y, w, h = roi\n",
    "        \n",
    "        output.append(pool2d(feature_map[:, :, y:y+h+1, x:x+w+1], 4,1,0, pool_mode='max'))\n",
    "    return output\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_tensor = inputs\n",
    "    #test_tensor = test_tensor.view(1, 1, 8, 8)\n",
    "    rois = torch.tensor([[0, 0, 3, 3]])\n",
    "    rois = rois.view(1, -1, 4)\n",
    "    \n",
    "    my_out = roi_pooling(input_np, rois, (1, 1))\n",
    "    print(my_out )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6cdfdc99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[ True]],\n",
       "\n",
       "         [[ True]],\n",
       "\n",
       "         [[ True]]]]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_out == my_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecaf3fb",
   "metadata": {},
   "source": [
    "#  Batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "23e8d0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = inputs.view(3,-1)\n",
    "running_mean = torch.mean(mean, 1)\n",
    "var = inputs.view(3,-1)\n",
    "running_var = torch.var(var, 1)\n",
    "torch_out =torch.nn.functional.batch_norm(inputs, running_mean, running_var,weight=None, bias=None, training=False, momentum=0.1,eps=1e-05)\n",
    "torch_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8e238bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 32, 32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def batchnorm_forward(x,  running_mean, running_var, mode , momentum,eps ):\n",
    "    N, C, H, W = x.shape\n",
    "    out= None\n",
    "    if mode == 'train':\n",
    "        sample_mean = running_mean\n",
    "        sample_var = running_var\n",
    "\n",
    "        # Normalization followed by Affine transformation\n",
    "        x_normalized = (x[0,:,:,:] - sample_mean.reshape(( 1,C, 1, 1)))/np.sqrt(sample_var.reshape(( 1,C, 1, 1)) + eps)\n",
    "        out = x_normalized\n",
    "\n",
    "        # Estimate running average of mean and variance to use at test time\n",
    "        running_mean = momentum * running_mean + (1 - momentum) * sample_mean\n",
    "        running_var = momentum * running_var + (1 - momentum) * sample_var\n",
    "        \n",
    "    elif mode == 'test':\n",
    "        # normalize using running average\n",
    "        running_mean = momentum * running_mean + (1 - momentum) * running_mean\n",
    "        running_var = momentum * running_var + (1 - momentum) * running_var\n",
    "        x_normalized = (x[0,:,:,:] - running_mean.reshape(( 1,C, 1, 1)))/np.sqrt(running_var.reshape((1, C, 1, 1)) + eps)\n",
    "        # Learned affine transformation\n",
    "        out = x_normalized \n",
    "    return out\n",
    "running_mean = running_mean.numpy()\n",
    "running_var = running_var.numpy()\n",
    "my_out = batchnorm_forward(input_np,  running_mean, running_var,  'test', 0.1,1e-05 )\n",
    "my_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f48051f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_out - my_out<=0.000001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8c281f",
   "metadata": {},
   "source": [
    "# Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1953e23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3668)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.randint(3, (1,32,32), dtype=torch.int64)\n",
    "torch_out = torch.nn.functional.cross_entropy(inputs, target, weight=None,\n",
    "size_average=None, ignore_index=-100, reduce=None,reduction='mean')\n",
    "torch_out                                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9077931d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3668)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_loss(softmax, target):\n",
    "    loss_list = torch.zeros([len(inputs)])\n",
    "    for k in range(len(softmax)):\n",
    "        loss = 0\n",
    "        for i in range(target[k].shape[1]):\n",
    "            for j in range(target.shape[2]):\n",
    "                index = target[k, i, j]\n",
    "                num = softmax[k, index, i ,j]\n",
    "                loss -= num\n",
    "        loss_list[k] = -loss / target.shape[1] / target.shape[2]\n",
    "    return loss_list.mean()\n",
    "\n",
    "def cross_entropy(x, target):\n",
    "    #compute softmax\n",
    "    x_log_softmax = torch.zeros(x.shape)\n",
    "    for i in range(len(x)):\n",
    "        exp = torch.exp(x[i])\n",
    "        sum = torch.sum(exp, dim=0)\n",
    "        softmax = exp/sum\n",
    "        x_log_softmax[i] = -torch.log(softmax)\n",
    "\n",
    "    ce = compute_loss(x_log_softmax, target)\n",
    "    return ce\n",
    "my_out = cross_entropy(inputs, target)\n",
    "my_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6824e13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_out == my_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fc54ad",
   "metadata": {},
   "source": [
    "# MSE Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e7b4e9",
   "metadata": {},
   "source": [
    "\n",
    "Input: (N, *)(N,∗) where *∗ means, any number of additional dimensions\n",
    "\n",
    "Target: (N, *)(N,∗) , same shape as the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fcf7d0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9392)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.randn(1,3, 32, 32)\n",
    "torch_out =torch.nn.functional.mse_loss(inputs, target, size_average=None,reduce=None, reduction='mean')\n",
    "torch_out  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "53c187d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9392)\n"
     ]
    }
   ],
   "source": [
    "def mse_loss(input, target):\n",
    "    square = (input - target)**2\n",
    "    return square.mean()\n",
    "my_out = mse_loss(inputs, target)\n",
    "print(my_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4b7b5f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_out == my_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ae7769",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
